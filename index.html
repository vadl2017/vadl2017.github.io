<!DOCTYPE html>
  
  
  
  
   <html class="no-js"> 

  <head lang="en-us">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,maximum-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=10" />
    <title>VADL 2017: Workshop on Visual Analytics for Deep Learning</title>
    <meta name="generator" content="Hugo 0.20.1" />

    
    <meta name="description" content="VADL Workshop for IEEE VIS 2017">
    
    <link rel="canonical" href="https://vadl2017.github.io/">
    

    <meta property="og:url" content="https://vadl2017.github.io/">
    <meta property="og:title" content="VADL 2017: Workshop on Visual Analytics for Deep Learning">
    
    <meta name="apple-mobile-web-app-title" content="VADL 2017: Workshop on Visual Analytics for Deep Learning">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <link rel="shortcut icon" type="image/x-icon" href="https://vadl2017.github.io/images/favicon.ico">
    <link rel="icon" type="image/x-icon" href="https://vadl2017.github.io/images/favicon.ico">

    <style>
      @font-face {
        font-family: 'Icon';
        src: url('https://vadl2017.github.io/fonts/icon.eot');
        src: url('https://vadl2017.github.io/fonts/icon.eot')
               format('embedded-opentype'),
             url('https://vadl2017.github.io/fonts/icon.woff')
               format('woff'),
             url('https://vadl2017.github.io/fonts/icon.ttf')
               format('truetype'),
             url('https://vadl2017.github.io/fonts/icon.svg')
               format('svg');
        font-weight: normal;
        font-style: normal;
      }
    </style>

    <link rel="stylesheet" href="https://vadl2017.github.io/stylesheets/application.css">
    <link rel="stylesheet" href="https://vadl2017.github.io/stylesheets/temporary.css">
    <link rel="stylesheet" href="https://vadl2017.github.io/stylesheets/palettes.css">
    <link rel="stylesheet" href="https://vadl2017.github.io/stylesheets/highlight/highlight.css">

    
    
    
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto:400,700|Ubuntu&#43;Mono">
    <style>
      body, input {
        font-family: 'Noto', Helvetica, Arial, sans-serif;
      }
      pre, code {
        font-family: 'Ubuntu Mono', 'Courier New', 'Courier', monospace;
      }
    </style>

    
    <script src="https://vadl2017.github.io/javascripts/modernizr.js"></script>

    
    <link href="https://vadl2017.github.io/index.xml" rel="alternate" type="application/rss+xml" title="VADL 2017: Workshop on Visual Analytics for Deep Learning" />
    <link href="https://vadl2017.github.io/index.xml" rel="feed" type="application/rss+xml" title="VADL 2017: Workshop on Visual Analytics for Deep Learning" />
    

  </head>
  <body class="palette-primary-teal palette-accent-red">




<div class="backdrop">
	<div class="backdrop-paper"></div>
</div>

<input class="toggle" type="checkbox" id="toggle-drawer">
<input class="toggle" type="checkbox" id="toggle-search">
<label class="toggle-button overlay" for="toggle-drawer"></label>

<header class="header">
	<nav aria-label="Header">
  <div class="bar default">
    <div class="button button-menu" role="button" aria-label="Menu">
      <label class="toggle-button icon icon-menu" for="toggle-drawer">
        <span></span>
      </label>
    </div>
    <div class="stretch">
      <div class="title">
        VADL 2017: Workshop on Visual Analytics for Deep Learning
      </div>
    </div>

    

    
    
        
  </div>
  <div class="bar search">
    <div class="button button-close" role="button" aria-label="Close">
      <label class="toggle-button icon icon-back" for="toggle-search"></label>
    </div>
    <div class="stretch">
      <div class="field">
        <input class="query" type="text" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck>
      </div>
    </div>
    <div class="button button-reset" role="button" aria-label="Search">
      <button class="toggle-button icon icon-close" id="reset-search"></button>
    </div>
  </div>
</nav>
</header>

<main class="main">
	<div class="drawer">
		<nav aria-label="Navigation">
  <a href="https://vadl2017.github.io" class="project">
    <div class="banner">
      
      <div class="name">
        <strong>VADL 2017: Workshop on Visual Analytics for Deep Learning </strong>
        
      </div>
    </div>
  </a>

  <div class="scrollable">
    <div class="wrapper">
      

      <div class="toc">
        
        <ul>
          




<li>
  
    



<a class="current" title="About" href="https://vadl2017.github.io/">
	
	About
</a>


<ul id="scrollspy">
</ul>


  
</li>


        </ul>
        

        
        <hr>
	
        
        <ul>
          

          

          
          <li>
            <a href="mailto:intuinno@gmail.com" title="Email of intuinno@gmail.com">
              Contact via email
            </a>
          </li>
          
        </ul>
        
      </div>
    </div>
  </div>
</nav>

	</div>

	<article class="article">
		<div class="wrapper">
			
				<h1> </h1>

				

<h2 id="call-for-papers">Call for Papers</h2>

<p>Recently, deep neural networks have been achieving breakthroughs in various major artificial intelligence tasks such as machine translation, image understanding, speech recognition, and so on. In these tasks, deep neural networks reached the level of an accuracy comparable to or even better than humans’ performance. However, understanding the deep neural networks is challenging due to their large network size and many parameters.</p>

<p>VADL, the workshop on visual analytics for deep learning, is a half-day workshop held in conjunction with <a href="http://ieeevis.org/">IEEE VIS 2017 Conference</a> in Phoenix, AZ. The primary goal of the workshop is to bridge the gap by bringing together researchers from both machine learning and visual analytics fields, which allows us to push the boundary of deep learning. The workshop should provide an opportunity to discuss and explore ways to harmonize the power of automated techniques and exploratory nature of interactive visualization.</p>

<h2 id="topics-of-interest">Topics of Interest</h2>

<p>In this call, we look for papers related to visual analytics for deep learning. Topics of interest include, but are not limited to:</p>

<ul>
<li>User-adaptive approaches to deep neural networks</li>
<li>Coupling of deep learning-based systems with interactive visualization</li>
<li>Visualization to improve deep learning algorithms and models</li>
<li>Coordinated visualizations for deep learning</li>
<li>Systems, languages, and architectures for interactive deep learning</li>
<li>Collaborative analysis of deep network networks</li>
<li>Real-time visualization of streaming data handling in deep learning</li>
<li>Visualization of uncertainty in deep neural networks</li>
<li>Domain-specific applications of visual analysis of deep neural networks (e.g. retail, healthcare, government, etc.)</li>
<li>Studies and evaluation of deep learning visualization techniques, systems, metrics, and benchmarks</li>
</ul>

<h2 id="submission-information">Submission Information</h2>

<p>All papers will be peer reviewed, single-blinded. We welcome many kinds of papers, including (but not limited to):</p>

<ul>
<li>Novel research papers</li>
<li>Demo papers</li>
<li>Work-in-progress papers</li>
<li>Visionary papers (white papers)</li>
<li>Position papers</li>
<li>Relevant work that has been previously published</li>
<li>Work that will be presented at the main conference of IEEE VIS’17</li>
</ul>

<p>Authors should clearly indicate in their abstracts the kinds of submissions, to help reviewers better understand their contributions. Submissions must be in PDF, written in English, no more than 10 pages long — shorter papers such as 2 to 4 pages are welcome — and formatted using the <a href="http://junctionpublishing.org/vgtc/Tasks/camera.html">IEEE &ldquo;Conference Style&rdquo; template</a>.
The accepted papers will be posted on the workshop website and will be included in the IEEE VIS’17 electronic proceedings USB stick.
For accepted papers, at least one author must attend the workshop to present the work.</p>

<h2 id="important-dates">Important Dates</h2>

<ul>
<li>Submission: <strong>July 21, 2017</strong></li>
<li>Author notification: August 4, 2017</li>
<li>Camera-ready: August 18, 2015</li>
<li>Workshop date: October 1 or 2</li>
</ul>

<h2 id="schedule-of-events">Schedule of Events</h2>

<p>The tentative schedule is as follows:
- 09:00-09:10 Opening remark
- 09:10-09:35 Invited talk 1
- 09:35-10:00 Invited talk 2
- 10:00-10:25 Invited talk 3
- 10:25-10:50 Break (30 mins)
- 10:50-11:10 Paper presentation 1
- 11:10-11:30 Paper presentation 2
- 11:30-11:50 Paper presentation 3
- 11:50-12:10 Paper presentation 4
- 12:10-14:00 Poster Session</p>

<h2 id="organizers">Organizers</h2>

<h3 id="jaegul-choo-https-sites-google-com-site-jaegulchoo"><a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a></h3>

<p>Jaegul Choo is currently an assistant professor in the Dept. of Computer Science and Engineering at Korea University. He earned his Ph.D at Georgia Tech in 2013, where he continued working as a research scientist until 2015. His main research lies in leveraging both machine learning and interactive visualization for machine learning and data mining. He has developed interpretable, interactive machine learning approaches as well as sophisticated visual analytics systems utilizing them for supporting complicated human-in-the-loop analysis tasks. Jaegul has published in premier venues in data mining, machine learning, and visual analytics such as TVCG, CG&amp;A, VAST, KDD, WWW, WSDM, ICDM, ICWSM, SDM, AAAI, and IJCAI. He received the Best Student Paper Award at ICDM in 2016 and the Best Poster Award at IEEE VAST (as part of IEEE VIS) in 2014.</p>

<h3 id="shixia-liu-http-shixialiu-com"><a href="http://shixialiu.com/">Shixia Liu</a></h3>

<p>Shixia Liu is an associate professor in the School of Software, Tsinghua University. Her research interests include visual text analytics, visual social analytics, visual model analytics, and text mining. She has published over 40 refereed papers in the leading journals and conferences such as IEEE Transactions on Visualization and Computer Graphics, IEEE Transactions on Knowledge and Data Engineering, IEEE InfoVis, IEEE VAST, KDD, and WWW. Shixia is the associate editor of IEEE Transactions on Visualization and Computer Graphics and on the editorial board of Information Visualization. She is the papers co-chair of IEEE VAST 2016 and 2017 and was the program co-chair of PacifcVis 2014 and VINCI 2012. She was the guest editor of ACM Transactions on Intelligent Systems and Technology and Tsinghua Science and Technology. Shixia received honorable mention awards at ACM CIKM 2009 and IEEE VAST 2014.</p>

<h3 id="jason-yosinski-http-yosinski-com"><a href="http://yosinski.com/">Jason Yosinski</a></h3>

<p>Jason Yosinski is a machine learning researcher and founding member of Uber AI Labs, where he uses neural networks and machine learning to build better and more understandable AI. He was previously a PhD student and NASA Space Technology Research Fellow working at the Cornell Creative Machines Lab, the University of Montreal, the Caltech Jet Propulsion Laboratory, and Google DeepMind. His work on AI has been featured on NPR, Fast Company, the Economist, TEDx, and on the BBC. When not doing research, Mr. Yosinski enjoys tricking middle school students into learning math while they play with robots.</p>

<h3 id="deokgun-park-http-intuinno-com"><a href="http://intuinno.com/">Deokgun Park</a></h3>

<p>Deokgun Park is a doctoral candidate advised by Niklas Elmqvist in the Department of Computer Science at University of Maryland, College Park. He is interested in supporting humans for solving open-ended tasks in text mining using visual analytics. He approaches the problem of evaluating the unstructured output of deep learning models as an open-ended task, where humans can point the weak area of the model and teach the model to improve it. Deokgun has published more than 10 academic papers and registered more than 20 patents. Deokgun received an honorable mention award at ACM CHI 2016 and Best Poster Award at LabAutomation 2002.</p>

<h2 id="program-committee">Program Committee</h2>

			

			<aside class="copyright" role="note">
				
				&copy; 2017 Released under the MIT license &ndash;
				
				Documentation built with
				<a href="https://www.gohugo.io" target="_blank">Hugo</a>
				using the
				<a href="http://github.com/digitalcraftsman/hugo-material-docs" target="_blank">Material</a> theme.
			</aside>

			<footer class="footer">
				



<nav class="pagination" aria-label="Footer">
  <div class="previous">
  </div>

  
  
  <div class="next">
      <a href="https://vadl2017.github.io/tags/" title="Tags">
        <span class="direction">
          Next
        </span>
        <div class="page">
          <div class="stretch">
            <div class="title">
              Tags
            </div>
          </div>
          <div class="button button-next" role="button" aria-label="Next">
            <i class="icon icon-forward"></i>
          </div>
        </div>
      </a>
  </div>
</nav>



			</footer>
		</div>
	</article>

	<div class="results" role="status" aria-live="polite">
		<div class="scrollable">
			<div class="wrapper">
				<div class="meta"></div>
				<div class="list"></div>
			</div>
		</div>
	</div>
</main>

    <script>
    
      var base_url = '';
      var repo_id  = '';
    
    </script>

    <script src="https://vadl2017.github.io/javascripts/application.js"></script>
    

    <script>
      /* Add headers to scrollspy */
      var headers   = document.getElementsByTagName("h2");
      var scrollspy = document.getElementById('scrollspy');

      if(scrollspy) {
        if(headers.length > 0) {
          for(var i = 0; i < headers.length; i++) {
            var li = document.createElement("li");
            li.setAttribute("class", "anchor");

            var a  = document.createElement("a");
            a.setAttribute("href", "#" + headers[i].id);
            a.setAttribute("title", headers[i].innerHTML);
            a.innerHTML = headers[i].innerHTML;

            li.appendChild(a)
            scrollspy.appendChild(li);
          }
        } else {
          scrollspy.parentElement.removeChild(scrollspy)
        }


        /* Add permanent link next to the headers */
        var headers = document.querySelectorAll("h1, h2, h3, h4, h5, h6");

        for(var i = 0; i < headers.length; i++) {
            var a = document.createElement("a");
            a.setAttribute("class", "headerlink");
            a.setAttribute("href", "#" + headers[i].id);
            a.setAttribute("title", "Permanent link")
            a.innerHTML = "#";
            headers[i].appendChild(a);
        }
      }
    </script>

    

    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>

